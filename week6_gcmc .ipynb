{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pyhton 3.6.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 85% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data):\n",
    "    \"\"\"\n",
    "    Map data to proper indices in case they are not in a continues [0, N) range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.int32 arrays\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mapped_data : np.int32 arrays\n",
    "    n : length of mapped_data\n",
    "\n",
    "    \"\"\"\n",
    "    uniq = list(set(data))\n",
    "\n",
    "    id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
    "    data = np.array(list(map(lambda x: id_dict[x], data)))\n",
    "    n = len(uniq)\n",
    "\n",
    "    return data, id_dict, n\n",
    "\n",
    "def preprocess_user_item_features(u_features, v_features):\n",
    "    \"\"\"\n",
    "    Creates one big feature matrix out of user features and item features.\n",
    "    Stacks item features under the user features.\n",
    "    \"\"\"\n",
    "\n",
    "    zero_csr_u = sp.csr_matrix((u_features.shape[0], v_features.shape[1]), dtype=u_features.dtype) #943, 1682\n",
    "    zero_csr_v = sp.csr_matrix((v_features.shape[0], u_features.shape[1]), dtype=v_features.dtype) #1682, 943\n",
    "\n",
    "    u_features = sp.hstack([u_features, zero_csr_u], format='csr') #(943, 943+1682)\n",
    "    v_features = sp.hstack([zero_csr_v, v_features], format='csr') #(1682, 1682+943)\n",
    "\n",
    "    return u_features, v_features\n",
    "\n",
    "def globally_normalize_bipartite_adjacency(adjacencies, verbose=False, symmetric=True):\n",
    "    \"\"\" \n",
    "    Globally Normalizes set of bipartite adjacency matrices (calculate c_ij) \n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print('Symmetrically normalizing bipartite adj')\n",
    "    # degree_u and degree_v are row and column sums of adj+I\n",
    "\n",
    "    adj_tot = np.sum(adj for adj in adjacencies)\n",
    "    degree_u = np.asarray(adj_tot.sum(1)).flatten() # sum by col (943,)\n",
    "    degree_v = np.asarray(adj_tot.sum(0)).flatten() # sum by row (1682,)\n",
    "\n",
    "    # set zeros to inf to avoid dividing by zero\n",
    "    degree_u[degree_u == 0.] = np.inf \n",
    "    degree_v[degree_v == 0.] = np.inf \n",
    "    \n",
    "    degree_u_inv_sqrt = 1. / np.sqrt(degree_u) # (943,)\n",
    "    degree_v_inv_sqrt = 1. / np.sqrt(degree_v) # (1682,)\n",
    "     \n",
    "    degree_u_inv_sqrt_mat = sp.diags([degree_u_inv_sqrt], [0]) #[0]: 대각성분 시작 인덱스 \n",
    "    degree_v_inv_sqrt_mat = sp.diags([degree_v_inv_sqrt], [0])\n",
    "\n",
    "    degree_u_inv = degree_u_inv_sqrt_mat.dot(degree_u_inv_sqrt_mat)\n",
    "\n",
    "    if symmetric:\n",
    "        # symmetric normalization\n",
    "        adj_norm = [degree_u_inv_sqrt_mat.dot(adj).dot(degree_v_inv_sqrt_mat) for adj in adjacencies]\n",
    "\n",
    "    else:\n",
    "        # left normalization \n",
    "        adj_norm = [degree_u_inv.dot(adj) for adj in adjacencies] \n",
    "\n",
    "    return adj_norm\n",
    "\n",
    "\n",
    "def normalize_features(feat):\n",
    "\n",
    "    degree = np.asarray(feat.sum(1)).flatten()\n",
    "\n",
    "    # set zeros to inf to avoid dividing by zero\n",
    "    degree[degree == 0.] = np.inf\n",
    "\n",
    "    degree_inv = 1. / degree\n",
    "    degree_inv_mat = sp.diags([degree_inv], [0])\n",
    "    feat_norm = degree_inv_mat.dot(feat)\n",
    "\n",
    "    if feat_norm.nnz == 0:\n",
    "        print('ERROR: normalized adjacency matrix has only zero entries!!!!!')\n",
    "        exit\n",
    "\n",
    "    return feat_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비 \n",
    "* http://files.grouplens.org/datasets/movielens/  \n",
    "* ml-100k.zip  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 로드 \n",
    "* figue 1 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (80000, 4)\n",
      "test shape: (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "path = './ml-100k/'\n",
    "dtypes = {'u_nodes': np.int32, 'v_nodes': np.int32, 'ratings': np.float32, 'timestamp': np.float64}\n",
    "\n",
    "data_train = pd.read_csv(path+'u1.base', sep='\\t', header=None,\n",
    "                         names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "data_test = pd.read_csv(path+'u1.test', sep='\\t', header=None,\n",
    "                        names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "print('train shape:', data_train.shape)\n",
    "print('test shape:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_nodes</th>\n",
       "      <th>v_nodes</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>874965758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>876893171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>878542960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>876893119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>889751712.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_nodes  v_nodes  ratings    timestamp\n",
       "0        1        1      5.0  874965758.0\n",
       "1        1        2      3.0  876893171.0\n",
       "2        1        3      4.0  878542960.0\n",
       "3        1        4      3.0  876893119.0\n",
       "4        1        5      3.0  889751712.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_nodes</th>\n",
       "      <th>v_nodes</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>887431973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>875693118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>878542960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>874965706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>875073198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_nodes  v_nodes  ratings    timestamp\n",
       "0        1        6      5.0  887431973.0\n",
       "1        1       10      3.0  875693118.0\n",
       "2        1       12      5.0  878542960.0\n",
       "3        1       14      5.0  874965706.0\n",
       "4        1       17      3.0  875073198.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df -> array로 변경 \n",
    "\n",
    "# train data\n",
    "data_array_train = data_train.values.tolist()\n",
    "data_array_train = np.array(data_array_train) # shape:(80000, 4)\n",
    "\n",
    "# test data\n",
    "data_array_test = data_test.values.tolist() \n",
    "data_array_test = np.array(data_array_test)   # shape:(20000, 4)\n",
    "\n",
    "# train + test data \n",
    "data_array = np.concatenate([data_array_train, data_array_test], axis=0) # shape:(100000, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_nodes</th>\n",
       "      <th>v_nodes</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>874965758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>876893171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>878542960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>876893119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>889751712.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_nodes  v_nodes  ratings    timestamp\n",
       "0        1        1      5.0  874965758.0\n",
       "1        1        2      3.0  876893171.0\n",
       "2        1        3      4.0  878542960.0\n",
       "3        1        4      3.0  876893119.0\n",
       "4        1        5      3.0  889751712.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.00000000e+00, 5.00000000e+00, 8.74965758e+08],\n",
       "       [1.00000000e+00, 2.00000000e+00, 3.00000000e+00, 8.76893171e+08],\n",
       "       [1.00000000e+00, 3.00000000e+00, 4.00000000e+00, 8.78542960e+08],\n",
       "       ...,\n",
       "       [9.43000000e+02, 1.18800000e+03, 3.00000000e+00, 8.88640250e+08],\n",
       "       [9.43000000e+02, 1.22800000e+03, 3.00000000e+00, 8.88640275e+08],\n",
       "       [9.43000000e+02, 1.33000000e+03, 3.00000000e+00, 8.88692465e+08]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 데이터 생성  \n",
    "#### user, item, rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num users: 943\n",
      "num items: 1682\n",
      "num ratings: 5\n"
     ]
    }
   ],
   "source": [
    "# user node\n",
    "u_nodes = data_array[:, 0].astype(dtypes['u_nodes'])\n",
    "# item node\n",
    "v_nodes = data_array[:, 1].astype(dtypes['v_nodes']) \n",
    "# rating node \n",
    "ratings = data_array[:, 2].astype(dtypes['ratings'])         \n",
    "# ranting class \n",
    "class_values = np.sort(np.unique(ratings))\n",
    "\n",
    "print('num users:', len(np.unique(u_nodes)))\n",
    "print('num items:', len(np.unique(v_nodes)))\n",
    "print('num ratings:', len(np.unique(ratings)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user, item id mapping dictionary \n",
    "u_nodes, u_dict, num_users = map_data(u_nodes) \n",
    "v_nodes, v_dict, num_items = map_data(v_nodes) \n",
    "rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "# change data type \n",
    "u_nodes, v_nodes = u_nodes.astype(np.int64), v_nodes.astype(np.int32)\n",
    "\n",
    "# set unobserved value\n",
    "neutral_rating = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user-item matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.full((num_users, num_items), neutral_rating, dtype=np.int32) # shape: (943, 1682)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  2,  3, ..., -1, -1, -1],\n",
       "       [ 3, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [ 4, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1,  4, -1, ..., -1, -1, -1]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[u_nodes, v_nodes] = np.array([rating_dict[r] for r in ratings]) # 값 부여 \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  2,  3, ..., -1, -1, -1], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape([-1]) # (1586126,) = (num_users*num_items, )\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, test, validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = data_array_train.shape[0]   # 80000\n",
    "\n",
    "num_test = data_array_test.shape[0]     # 20000\n",
    "num_val = int(np.ceil(num_train * 0.2)) # 16000\n",
    "num_train = num_train - num_val         # 64000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, item node pairs \n",
    "pairs_nonzero = np.array([[u, v] for u, v in zip(u_nodes, v_nodes)])  # shape: (100000, 2)\n",
    "pairs_nonzero_train = pairs_nonzero[0:num_train+num_val]              # shape: (80000, 2)\n",
    "pairs_nonzero_test = pairs_nonzero[num_train+num_val:]                # shape: (20000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   1],\n",
       "       [  0,   2],\n",
       "       ...,\n",
       "       [458, 933],\n",
       "       [459,   9],\n",
       "       [461, 681]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_nonzero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index which has nonzero value\n",
    "idx_nonzero = np.array([u * num_items + v for u, v in pairs_nonzero]) # shape: (100000,) ; labels에서 -1이 아닌 index\n",
    "idx_nonzero_train = idx_nonzero[0:num_train+num_val]                  # shape: (80000,)\n",
    "idx_nonzero_test = idx_nonzero[num_train+num_val:]                    # shape: (20000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 771289, 772047, 776083])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nonzero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw random index to shuffle train\n",
    "np.random.seed(42)\n",
    "rand_idx = [i for i in range(len(idx_nonzero_train))]\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "pairs_nonzero_train = pairs_nonzero_train[rand_idx]\n",
    "idx_nonzero_train = idx_nonzero_train[rand_idx]\n",
    "\n",
    "pairs_nonzero = np.concatenate([pairs_nonzero_train, pairs_nonzero_test], axis=0)\n",
    "idx_nonzero = np.concatenate([idx_nonzero_train, idx_nonzero_test], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, validation for nonzero index \n",
    "val_idx = idx_nonzero[0:num_val]\n",
    "train_idx = idx_nonzero[num_val: num_val + num_train]\n",
    "test_idx = idx_nonzero[num_val + num_train:]\n",
    "\n",
    "# train, test, validation for pairs\n",
    "val_pairs_idx = pairs_nonzero[0:num_val]                      # (16000, 2)\n",
    "train_pairs_idx = pairs_nonzero[num_val: num_val + num_train] # (64000, 2)\n",
    "test_pairs_idx = pairs_nonzero[num_val + num_train:]          # (20000, 2)\n",
    "\n",
    "val_u_indices, val_v_indices = val_pairs_idx.transpose()        # (16000,), (16000,)\n",
    "train_u_indices, train_v_indices = train_pairs_idx.transpose()  # (64000,), (64000,)\n",
    "test_u_indices, test_v_indices = test_pairs_idx.transpose()     # (20000,), (20000,)\n",
    "\n",
    "# train, test, validation for labels\n",
    "val_labels = labels[val_idx]\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adjacency matrix\n",
    "* page2. 오른쪽 상단의 M_r 메트릭스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train index에만 rating 부여 (M_r matrix)\n",
    "rating_mx_train = np.zeros(num_users * num_items, dtype=np.float32)         # (1586126,)\n",
    "rating_mx_train[train_idx] = labels[train_idx].astype(np.float32) + 1.      \n",
    "rating_mx_train = csr_matrix(rating_mx_train.reshape(num_users, num_items)) # (943, 1682) \n",
    "\n",
    "rating_mx_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 사이드 정보 데이터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item(movie) side feature: genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item(movie) features(genres)\n",
    "names = ['movie id', 'movie title', 'release date', 'video release date',\n",
    "         'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "         'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "         'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "         'Thriller', 'War', 'Western']\n",
    "\n",
    "movie_df = pd.read_csv(path+'u.item', sep=r'|', header=None, names=names, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDb URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id        movie title release date  video release date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDb URL  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "\n",
       "   Adventure  Animation  Childrens  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          0          1          1  ...        0          0       0        0   \n",
       "1          1          0          0  ...        0          0       0        0   \n",
       "2          0          0          0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Childrens', 'Comedy', 'Crime',\n",
       "       'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
       "       'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
       "       'Western'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_headers = movie_df.columns.values[6:]\n",
    "num_genres = genre_headers.shape[0] # 18개  \n",
    "genre_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_side_features_ = np.zeros((num_items, num_genres), dtype=np.float32) #(1682, 18) \n",
    "v_side_features_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for movie_id, genre_one_hot_vec in zip(movie_df['movie id'].values.tolist(), movie_df[genre_headers].values.tolist()):\n",
    "    if movie_id in v_dict.keys():\n",
    "        v_side_features_[v_dict[movie_id],:] = genre_one_hot_vec \n",
    "v_side_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie id                                                              1\n",
       "movie title                                            Toy Story (1995)\n",
       "release date                                                01-Jan-1995\n",
       "video release date                                                  NaN\n",
       "IMDb URL              http://us.imdb.com/M/title-exact?Toy%20Story%2...\n",
       "unknown                                                               0\n",
       "Action                                                                0\n",
       "Adventure                                                             0\n",
       "Animation                                                             1\n",
       "Childrens                                                             1\n",
       "Comedy                                                                1\n",
       "Crime                                                                 0\n",
       "Documentary                                                           0\n",
       "Drama                                                                 0\n",
       "Fantasy                                                               0\n",
       "Film-Noir                                                             0\n",
       "Horror                                                                0\n",
       "Musical                                                               0\n",
       "Mystery                                                               0\n",
       "Romance                                                               0\n",
       "Sci-Fi                                                                0\n",
       "Thriller                                                              0\n",
       "War                                                                   0\n",
       "Western                                                               0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_side_features_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user side features: age, gender, occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
    "users_df = pd.read_csv(path+'u.user', sep= r'|', header=None, names=names, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id  age gender  occupation zip code\n",
       "0        1   24      M  technician    85711\n",
       "1        2   53      F       other    94043\n",
       "2        3   23      M      writer    32067\n",
       "3        4   24      M  technician    43537\n",
       "4        5   33      F       other    15213"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age \n",
    "age = users_df['age'].values\n",
    "age_max = age.max()\n",
    "\n",
    "# gender \n",
    "gender_dict = {'M': 0., 'F': 1.}\n",
    "\n",
    "# occupation \n",
    "occupation = set(users_df['occupation'].values.tolist())\n",
    "occupation_dict = {f: i for i, f in enumerate(occupation, start=2)} #21개 \n",
    "\n",
    "num_feats = 2 + len(occupation_dict) #23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_side_features_ = np.zeros((num_users, num_feats), dtype=np.float32) #(943, 23) u_side_features로 변경 \n",
    "for _, row in users_df.iterrows():\n",
    "    u_id = row['user id']\n",
    "    if u_id in u_dict.keys():\n",
    "        # age\n",
    "        u_side_features_[u_dict[u_id], 0] = row['age'] / np.float(age_max)\n",
    "        # gender\n",
    "        u_side_features_[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
    "        # occupation\n",
    "        u_side_features_[u_dict[u_id], occupation_dict[row['occupation']]] = 1.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, user id             15\n",
       " age                 49\n",
       " gender               F\n",
       " occupation    educator\n",
       " zip code         97301\n",
       " Name: 14, dtype: object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(users_df.iterrows())[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6712329, 1.       , 0.       , 0.       , 0.       , 1.       ,\n",
       "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "       0.       , 0.       , 0.       , 0.       , 0.       ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_side_features_[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user side features shape: (943, 23)\n",
      "item side features shape: (1682, 18)\n"
     ]
    }
   ],
   "source": [
    "# to csr matrix \n",
    "u_side_features_ = csr_matrix(u_side_features_)\n",
    "v_side_features_ = csr_matrix(v_side_features_)\n",
    "\n",
    "print(\"user side features shape: \"+str(u_side_features_.shape))\n",
    "print(\"item side features shape: \"+str(v_side_features_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize side features  \n",
    "u_features_side_ = normalize_features(u_side_features_) # 각 행별로 더해서 나눔 \n",
    "v_features_side_ = normalize_features(v_side_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2474227 , 0.        , 0.        , ..., 0.        , 0.75257736,\n",
       "        0.        ],\n",
       "       [0.26633164, 0.36683416, 0.        , ..., 0.        , 0.        ,\n",
       "        0.36683416],\n",
       "       [0.23958333, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.21505375, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2474227 , 0.37628868, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.23157896, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features_side_.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2474227 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.75257736, 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features_side_.toarray()[0] # (23,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user side features shape: (943, 41)\n",
      "item side features shape: (1682, 41)\n"
     ]
    }
   ],
   "source": [
    "# preprocess_user_item_features() 동작 방식 \n",
    "u_features_side, v_features_side = preprocess_user_item_features(u_features_side_, v_features_side_)\n",
    "\n",
    "print(\"user side features shape: \"+str(u_features_side.shape))\n",
    "print(\"item side features shape: \"+str(v_features_side.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2474227 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.75257736, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features_side.toarray()[0] #(23+18, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_features_side.toarray()[0] #(23+18, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_features_side = np.array(u_features_side.todense(), dtype=np.float32)\n",
    "v_features_side = np.array(v_features_side.todense(), dtype=np.float32)\n",
    "num_side_features = u_features_side.shape[1] #41 = 18+23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 노드 정보 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_csr_u = sp.identity(num_users, format='csr') #diagnal matrix \n",
    "id_csr_v = sp.identity(num_items, format='csr')\n",
    "\n",
    "u_features, v_features = preprocess_user_item_features(id_csr_u, id_csr_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of id_csr_u: (943, 943)\n",
      "shape of id_csr_v: (1682, 1682)\n",
      "shape of u_features: (943, 2625)\n",
      "shape of v_features: (1682, 2625)\n"
     ]
    }
   ],
   "source": [
    "print('shape of id_csr_u:', id_csr_u.shape)\n",
    "print('shape of id_csr_v:', id_csr_v.shape)\n",
    "\n",
    "print('shape of u_features:', u_features.shape)\n",
    "print('shape of v_features:', v_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_csr_u.toarray() # (943, 943)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess_user_item_features() 동작 방식 \n",
    "u_features.toarray() # (943, 2625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_nodes</th>\n",
       "      <th>v_nodes</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>874965758.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_nodes  v_nodes  ratings    timestamp\n",
       "0        1        1      5.0  874965758.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예시 \n",
    "data_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_features.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_features.toarray()[0][943]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. global normalization\n",
    "* page3. 수식(1)의 c_ij 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-4. global normalization\n",
    "numclass = 5\n",
    "support = []\n",
    "support_t = []\n",
    "\n",
    "# create M_r matrix for each rating \n",
    "for i in range(numclass):    \n",
    "    support_unnormalized = sp.csr_matrix(rating_mx_train == i+1, dtype=np.float32) # M_1, M_2, ...M_R (943, 1682)\n",
    "    support_unnormalized_transpose = support_unnormalized.T # (1682, 943)\n",
    "    \n",
    "    support.append(support_unnormalized)\n",
    "    support_t.append(support_unnormalized_transpose)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mx_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support[-1].toarray() # M_5와 동일 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### left normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계산 과정 그림 첨부 \n",
    "support = globally_normalize_bipartite_adjacency(support, symmetric=False)      # [[], [], ...]\n",
    "support_t = globally_normalize_bipartite_adjacency(support_t, symmetric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00819672, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.05555556, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00763359, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support[-1].toarray() # for rating 5 (943, 1682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_support = len(support) \n",
    "support = sp.hstack(support, format='csr')      #(943,  1682*num_support) = (943, 8410)\n",
    "support_t = sp.hstack(support_t, format='csr')  #(1682, 943*num_support)  = (1682, 4715)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-6. 인덱스 맞추기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all user and item nodes for train set\n",
    "train_u = list(set(train_u_indices)) # 943개 \n",
    "train_v = list(set(train_v_indices)) # 1614개 \n",
    "train_u_dict = {u_idx: i for i, u_idx in enumerate(train_u)}\n",
    "train_v_dict = {v_idx: i for i, v_idx in enumerate(train_v)}\n",
    "\n",
    "train_u_indices = np.array([train_u_dict[u_idx] for u_idx in train_u_indices]) #64000개 \n",
    "train_v_indices = np.array([train_v_dict[v_idx] for v_idx in train_v_indices]) #64000개 \n",
    "\n",
    "# for side features \n",
    "train_u_features_side = u_features_side[np.array(train_u)] #(943, 41)\n",
    "train_v_features_side = v_features_side[np.array(train_v)] #(1614, 41)\n",
    "\n",
    "# for adj matrix \n",
    "train_support = support[np.array(train_u)]     #(943, 8410)\n",
    "train_support_t = support_t[np.array(train_v)] #(1614, 4715)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all user and item nodes for test set\n",
    "test_u = list(set(test_u_indices)) # 459개\n",
    "test_v = list(set(test_v_indices)) # 1410개 \n",
    "test_u_dict = {n: i for i, n in enumerate(test_u)}\n",
    "test_v_dict = {n: i for i, n in enumerate(test_v)}\n",
    "\n",
    "test_u_indices = np.array([test_u_dict[u_idx] for u_idx in test_u_indices]) #20000개 \n",
    "test_v_indices = np.array([test_v_dict[v_idx] for v_idx in test_v_indices]) #20000개\n",
    "\n",
    "# for side features \n",
    "test_u_features_side = u_features_side[np.array(test_u)] #(459, 41)\n",
    "test_v_features_side = v_features_side[np.array(test_v)] #(1410, 41)\n",
    "\n",
    "# for adj matrix \n",
    "test_support = support[np.array(test_u)]      # (459, 1682*num_support) = (459, 8410)\n",
    "test_support_t = support_t[np.array(test_v)]  # (1410, 943*num_support) = (1410, 4715)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all user and item nodes for validation set\n",
    "val_u = list(set(val_u_indices)) #933개 \n",
    "val_v = list(set(val_v_indices)) #1351개 \n",
    "val_u_dict = {n: i for i, n in enumerate(val_u)}\n",
    "val_v_dict = {n: i for i, n in enumerate(val_v)}\n",
    "\n",
    "val_u_indices = np.array([val_u_dict[u_idx] for u_idx in val_u_indices]) #16000개\n",
    "val_v_indices = np.array([val_v_dict[v_idx] for v_idx in val_v_indices]) #16000개 \n",
    "\n",
    "# for side features \n",
    "val_u_features_side = u_features_side[np.array(val_u)] #(933, 41)\n",
    "val_v_features_side = v_features_side[np.array(val_v)] #(1351, 41)\n",
    " \n",
    "# for adj matrix \n",
    "val_support = support[np.array(val_u)]     #(933, 8410)\n",
    "val_support_t = support_t[np.array(val_v)] #(1351, 4715)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "* pseudo code \n",
    "* RecommenderSideInfoGAE() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholders = {\n",
    "    \n",
    "    # user, item index\n",
    "    'user_indices': tf.placeholder(tf.int32, shape=(None,)),\n",
    "    'item_indices': tf.placeholder(tf.int32, shape=(None,)),\n",
    "    \n",
    "    # user, item features \n",
    "    'u_features': tf.sparse_placeholder(tf.float32, shape=np.array(u_features.shape, dtype=np.int64)),\n",
    "    'v_features': tf.sparse_placeholder(tf.float32, shape=np.array(v_features.shape, dtype=np.int64)),\n",
    "    \n",
    "    # user, item side features \n",
    "    'u_features_side': tf.placeholder(tf.float32, shape=(None, num_side_features)),\n",
    "    'v_features_side': tf.placeholder(tf.float32, shape=(None, num_side_features)),\n",
    "     \n",
    "    # rating \n",
    "    'labels': tf.placeholder(tf.int32, shape=(None,)),\n",
    "    'class_values': tf.placeholder(tf.float32, shape=class_values.shape),\n",
    "    \n",
    "    # adj matrix \n",
    "    'support': tf.sparse_placeholder(tf.float32, shape=(None, None)),\n",
    "    'support_t': tf.sparse_placeholder(tf.float32, shape=(None, None)),\n",
    "   \n",
    "    # dropout \n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'u_features_nonzero': tf.placeholder(tf.int32, shape=()), \n",
    "    'v_features_nonzero': tf.placeholder(tf.int32, shape=()),\n",
    "\n",
    "    'weight_decay': tf.placeholder_with_default(0., shape=()),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    " def build():\n",
    "            \n",
    "        # ---------- layers for user ----------\n",
    "        \n",
    "        # gcn layer(encoder)\n",
    "        # ref   : page2 - (2)\n",
    "        # input : (943, 2625)\n",
    "        # output: (943, 500)\n",
    "        gcn_u_output = gcn_layer(u_features) \n",
    "        \n",
    "        \n",
    "        # dense1 layer(for side features)\n",
    "        # ref   : page4 - (10)\n",
    "        # input : (943, 41)\n",
    "        # output: (943, 10)\n",
    "        u_side_output = dense1(u_features_side) \n",
    "        \n",
    "        \n",
    "        # dense2 layer(for concat) \n",
    "        # ref   : page2 - (3)\n",
    "        # input : (943, 510)\n",
    "        # output: (943, 75)\n",
    "        input_u = concat([gcn_u_output, u_side_output])\n",
    "        u_latent_output = dense2(input_u)\n",
    "        \n",
    "      \n",
    "        # ---------- layers for item ----------\n",
    "    \n",
    "        # gcn layer(encoder)\n",
    "        # input : (1682, 2625)\n",
    "        # output: (1682, 500)\n",
    "        gcn_v_output = gcn_layer(v_features)\n",
    "        \n",
    "        \n",
    "        # dense1 layer(for side features)\n",
    "        # input : (1682, 41)\n",
    "        # output: (1682, 10)\n",
    "        v_side_output = dense1(v_features_side) \n",
    "        \n",
    "        \n",
    "        # dense2 layer(for concat)\n",
    "        # input : (1682, 510)\n",
    "        # output: (1682, 75)\n",
    "        input_v = concat([gcn_v_output, v_side_output])\n",
    "        v_latent_output = dense2(input_v)\n",
    "        \n",
    "        \n",
    "        # ----------- output layer ------------\n",
    "        \n",
    "        # decoder\n",
    "        # ref   : page 3 - (4)\n",
    "        # input : (943, 75), (1682, 75)\n",
    "        # output: (80000, 5)\n",
    "        output = decoder_layer([u_latent_output, v_latent_output])\n",
    "              \n",
    "        # ------------- learning --------------\n",
    "        \n",
    "        loss = cross_entropy(output, labels) \n",
    "        rmse = metric(output, labels)\n",
    "        AdamOptimizer.minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ours():\n",
    "\n",
    "    # gcn layer(encoder)\n",
    "    gcn_u_output, gcn_v_output = gcn_layer([u_features, v_features])\n",
    "\n",
    "    # dense1 layer(dense layer for side features)\n",
    "    u_side_output, v_side_output = dense1([u_features_side, v_features_side])\n",
    "\n",
    "    # dense2 layer(dense layer for concat) \n",
    "    input_u = concat([gcn_u_output, u_side_output])\n",
    "    input_v = concat([gcn_v_output, v_side_output])\n",
    "\n",
    "    u_latent_output, v_latent_output = dense2([input_u, input_v])\n",
    "\n",
    "    # output layer(decoder)\n",
    "    output = decoder_layer([u_latent_output, v_latent_output]) #(80000, num_class)\n",
    "\n",
    "    # learning \n",
    "    loss = cross_entropy(output, labels)\n",
    "    rmse = metric(output, labels)\n",
    "    AdamOptimizer.minimize(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
